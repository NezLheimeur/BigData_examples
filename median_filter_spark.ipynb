{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "functional-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "import imageio\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extended-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImg(path):\n",
    "    img = imageio.imread(path)\n",
    "    im = np.array(img,dtype='uint8')\n",
    "    return im\n",
    "\n",
    "def writeImg(path,buf):\n",
    "    imageio.imwrite(path,buf)\n",
    "\n",
    "def part_median_filter(local_data):\n",
    "    part_id = local_data[0]\n",
    "    first   = local_data[1]\n",
    "    end     = local_data[2]\n",
    "    buf     = local_data[3]\n",
    "    nx = buf.shape[0]\n",
    "    ny = buf.shape[1]\n",
    "    \n",
    "    # CREATE NEW BUF WITH MEDIAN FILTER SOLUTION\n",
    "    new_buf = np.zeros((end-first-1, ny-2, 3), dtype='uint8')\n",
    "    \n",
    "    print(\"test\", buf[1,1])\n",
    "    # TODO COMPUTE MEDIAN FILTER\n",
    "    for i in range(first+1, end):\n",
    "        for j in range(1, ny-1):\n",
    "            median = np.median(\n",
    "                (buf[i-1,j-1], buf[i-1,j], buf[i-1,j+1],\n",
    "                buf[i,j-1], buf[i,j], buf[i,j+1],\n",
    "                buf[i+1,j-1], buf[i+1,j], buf[i+1,j+1]),\n",
    "                axis=0)\n",
    "            imedian = np.array([int(k) for k in median])\n",
    "            new_buf[i-first-1,j-1,:] = imedian\n",
    "            \n",
    "    # RETURN LOCAL IMAGE PART\n",
    "    \n",
    "    return part_id,new_buf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "finished-psychology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE (128, 128, 3)\n",
      "NB PARTITIONS :  8\n",
      "CREATING NEW PICTURE FILE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # CREATE SPARKCONTEXT\n",
    "    sc = SparkContext()\n",
    "    sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "    data_dir = '.'\n",
    "    file = os.path.join(data_dir, 'lena_noisy.jpg')\n",
    "    img_buf = readImg(file)\n",
    "    print('SHAPE', img_buf.shape)\n",
    "    \n",
    "    nx = img_buf.shape[0]\n",
    "    ny = img_buf.shape[1]\n",
    "\n",
    "    # SPLT IMAGES IN NB_PARTITIONS PARTS\n",
    "    # Taking GHOST CELLS for each partition\n",
    "    # being the boundaries of the corresponding division\n",
    "    nb_partitions = 8\n",
    "    print(\"NB PARTITIONS : \", nb_partitions)\n",
    "    data = []\n",
    "    begin = 0\n",
    "    rest = nx % nb_partitions\n",
    "    for ip in range(nb_partitions):\n",
    "        block_size = int(nx / nb_partitions) + (1 if ip < rest else 0)\n",
    "        end = min(begin + block_size + 1, nx - 1)\n",
    "        data.append((ip, begin, end, img_buf))\n",
    "        begin = end - 1\n",
    "    \n",
    "    # PARALLEL MEDIAN FILTER COMPUTATION\n",
    "    data_rdd = sc.parallelize(data, nb_partitions)\n",
    "    result_rdd = data_rdd.map(part_median_filter)\n",
    "    result_data = result_rdd.collect()\n",
    "\n",
    "    print('CREATING NEW PICTURE FILE')\n",
    "    new_img_buf = np.zeros((nx, ny, 3), dtype='uint8')\n",
    "    new_img_buf[:,0,:] = img_buf[:,0,:]\n",
    "    new_img_buf[:,-1,:] = img_buf[:,-1,:]\n",
    "    new_img_buf[0,:,:] = img_buf[0,:,:]\n",
    "    new_img_buf[-1,:,:] = img_buf[-1,:,:]\n",
    "    \n",
    "    # COMPUTE NEW IMAGE RESULTS FROM RESULT RDD\n",
    "    result_data.sort(key=lambda x: x[0]) # sort the results according to their partition Id \n",
    "    parts = list(zip(*result_data))[1]\n",
    "    new_img_buf[1:-1,1:-1,:] = np.concatenate(parts)\n",
    "\n",
    "    filter_file = os.path.join(data_dir,'lena_filter.jpg')\n",
    "    writeImg(filter_file, new_img_buf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "plain-latin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (16, 126, 3)\n",
      "shape2 (126, 126, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape\",result_data[0][1].shape)\n",
    "print(\"shape2\",np.concatenate(parts).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-petite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
