{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_ml_spark.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "needed-reason"
      },
      "source": [
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import Row, SQLContext\n",
        "from pyspark import SparkFiles\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import os\n",
        "import pandas as pd\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "native-reception"
      },
      "source": [
        "#######################\n",
        "##CREATE SPARK CONTEXT#\n",
        "##CREATE SQL CONTEXT###\n",
        "#######################\n",
        "sc =SparkContext()\n",
        "sqlContext = SQLContext(sc)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "colonial-europe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5965aef3-881e-457e-df5f-fd5e07b1da75"
      },
      "source": [
        "#LOAD IRIS DATA\n",
        "\n",
        "data_dir=\".\"\n",
        "file = os.path.join(data_dir,\"iris.csv\")\n",
        "panda_df = pd.read_csv(file)\n",
        "\n",
        "iris_df=sqlContext.createDataFrame(panda_df)\n",
        "iris_df.printSchema()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- sepal_length: double (nullable = true)\n",
            " |-- sepal_width: double (nullable = true)\n",
            " |-- petal_length: double (nullable = true)\n",
            " |-- petal_width: double (nullable = true)\n",
            " |-- variety: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "steady-queens"
      },
      "source": [
        "#### Perform Data Analytics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "portable-native",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7684574-7ffa-4d1a-922a-b63169a4aa54"
      },
      "source": [
        "#See standard parameters\n",
        "iris_df.describe().show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+------------------+------------------+------------------+---------+\n",
            "|summary|      sepal_length|       sepal_width|      petal_length|       petal_width|  variety|\n",
            "+-------+------------------+------------------+------------------+------------------+---------+\n",
            "|  count|               150|               150|               150|               150|      150|\n",
            "|   mean| 5.843333333333332|3.0573333333333337| 3.758000000000001|1.1993333333333331|     null|\n",
            "| stddev|0.8280661279778628|0.4358662849366982|1.7652982332594664|0.7622376689603467|     null|\n",
            "|    min|               4.3|               2.0|               1.0|               0.1|   Setosa|\n",
            "|    max|               7.9|               4.4|               6.9|               2.5|Virginica|\n",
            "+-------+------------------+------------------+------------------+------------------+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lasting-violin"
      },
      "source": [
        "### Decision tree Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "norwegian-flesh"
      },
      "source": [
        "#### Prepare data for ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "variable-clinton"
      },
      "source": [
        "#Transform to a Data Frame for input to Machine Learing\n",
        "\n",
        "#stage 1: change the categorical feature to numerical one \n",
        "stringIndexer = StringIndexer(inputCol=\"variety\", outputCol=\"label\")\n",
        "\n",
        "\n",
        "#stage 2: generate one column \"features\" for all the features \n",
        "vectorAssembler = VectorAssembler(inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\\\n",
        "                                  outputCol=\"features\")\n",
        "\n",
        "#stage 3: create the model \n",
        "classifier_dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "#regroup the stages in a pipeline\n",
        "pipeline_dt = Pipeline(stages=[stringIndexer, vectorAssembler, classifier_dt])\n",
        "\n",
        "# split data\n",
        "(data_train, data_test) = iris_df.randomSplit([0.75, 0.25])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arabic-database"
      },
      "source": [
        "#### Perform Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enhanced-smoke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826b4319-20a1-4ace-ba4e-055e179e4326"
      },
      "source": [
        "# apply the pipeline to apply the transformation and train the model \n",
        "model_dt = pipeline_dt.fit(data_train)\n",
        "\n",
        "# make predictions by transforming the features dataframe into predictions dataframe\n",
        "predictions_dt = model_dt.transform(data_test)\n",
        "\n",
        "print(\"nb nodes in model dt: \",model_dt.stages[-1].numNodes)\n",
        "print(\"depth of model dt: \",model_dt.stages[-1].depth)\n",
        "\n",
        "predictions_dt.select(\"prediction\",\"label\", \"features\").show()\n",
        "\n",
        "#Evaluate accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n",
        "                    labelCol=\"label\",metricName=\"accuracy\")\n",
        "accuracy_dt = evaluator.evaluate(predictions_dt)    \n",
        "\n",
        "print(\"Test accuracy = \", accuracy_dt*100, \"%\")\n",
        "\n",
        "#Draw a confusion matrix\n",
        "predictions_dt.groupBy(\"label\",\"prediction\").count().show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb nodes in model dt:  17\n",
            "depth of model dt:  5\n",
            "+----------+-----+-----------------+\n",
            "|prediction|label|         features|\n",
            "+----------+-----+-----------------+\n",
            "|       2.0|  2.0|[4.4,2.9,1.4,0.2]|\n",
            "|       2.0|  2.0|[4.6,3.4,1.4,0.3]|\n",
            "|       2.0|  2.0|[4.8,3.0,1.4,0.1]|\n",
            "|       2.0|  2.0|[4.8,3.1,1.6,0.2]|\n",
            "|       2.0|  2.0|[4.9,3.6,1.4,0.1]|\n",
            "|       2.0|  2.0|[5.0,3.3,1.4,0.2]|\n",
            "|       2.0|  2.0|[5.1,3.3,1.7,0.5]|\n",
            "|       2.0|  2.0|[5.1,3.5,1.4,0.2]|\n",
            "|       2.0|  2.0|[5.1,3.8,1.5,0.3]|\n",
            "|       2.0|  2.0|[5.1,3.8,1.6,0.2]|\n",
            "|       2.0|  2.0|[5.2,3.4,1.4,0.2]|\n",
            "|       2.0|  2.0|[5.4,3.4,1.7,0.2]|\n",
            "|       2.0|  2.0|[5.4,3.9,1.3,0.4]|\n",
            "|       0.0|  0.0|[5.5,2.3,4.0,1.3]|\n",
            "|       2.0|  2.0|[5.5,4.2,1.4,0.2]|\n",
            "|       0.0|  0.0|[5.6,2.5,3.9,1.1]|\n",
            "|       0.0|  0.0|[5.7,2.8,4.5,1.3]|\n",
            "|       0.0|  0.0|[6.0,2.2,4.0,1.0]|\n",
            "|       0.0|  0.0|[6.1,2.8,4.7,1.2]|\n",
            "|       0.0|  0.0|[6.2,2.2,4.5,1.5]|\n",
            "+----------+-----+-----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Test accuracy =  100.0 %\n",
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  1.0|       1.0|   13|\n",
            "|  2.0|       2.0|   14|\n",
            "|  0.0|       0.0|   12|\n",
            "+-----+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neural-playlist"
      },
      "source": [
        "### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "common-thanks"
      },
      "source": [
        "#### Prepare data for ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gorgeous-discipline"
      },
      "source": [
        "#Transform to a Data Frame for input to Machine Learing\n",
        "\n",
        "#stage 1: as before\n",
        "#stage 2: as before \n",
        "                                  \n",
        "#stage 3: create the model \n",
        "classifier_rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "#regroup the stages in a pipeline\n",
        "pipeline_rf = Pipeline(stages=[stringIndexer, vectorAssembler, classifier_rf])\n",
        "\n",
        "# split data\n",
        "#(data_train, data_test) = iris_df.randomSplit([0.75, 0.25])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "technological-robin"
      },
      "source": [
        "#### Perform Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "another-laugh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3592a6-1986-4d9e-f342-819d72752b5f"
      },
      "source": [
        "# apply the pipeline to apply the transformation and train the model \n",
        "model_rf = pipeline_rf.fit(data_train)\n",
        "\n",
        "# make predictions by transforming the features dataframe into predictions dataframe\n",
        "predictions_rf = model_rf.transform(data_test)\n",
        "\n",
        "print(\"model info : \",model_rf.stages[-1])\n",
        "\n",
        "predictions_rf.select(\"prediction\",\"label\", \"features\").show()\n",
        "\n",
        "#Evaluate accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n",
        "                    labelCol=\"label\",metricName=\"accuracy\")\n",
        "accuracy_rf = evaluator.evaluate(predictions_rf)    \n",
        "\n",
        "print(\"Test accuracy = \", accuracy_rf*100, \"%\")\n",
        "\n",
        "#Draw a confusion matrix\n",
        "predictions_rf.groupBy(\"label\",\"prediction\").count().show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model info :  RandomForestClassificationModel: uid=RandomForestClassifier_bd811ce424c1, numTrees=20, numClasses=3, numFeatures=4\n",
            "+----------+-----+-----------------+\n",
            "|prediction|label|         features|\n",
            "+----------+-----+-----------------+\n",
            "|       2.0|  2.0|[4.4,2.9,1.4,0.2]|\n",
            "|       2.0|  2.0|[4.6,3.4,1.4,0.3]|\n",
            "|       2.0|  2.0|[4.8,3.0,1.4,0.1]|\n",
            "|       2.0|  2.0|[4.8,3.1,1.6,0.2]|\n",
            "|       2.0|  2.0|[4.9,3.6,1.4,0.1]|\n",
            "|       2.0|  2.0|[5.0,3.3,1.4,0.2]|\n",
            "|       2.0|  2.0|[5.1,3.3,1.7,0.5]|\n",
            "|       2.0|  2.0|[5.1,3.5,1.4,0.2]|\n",
            "|       2.0|  2.0|[5.1,3.8,1.5,0.3]|\n",
            "|       2.0|  2.0|[5.1,3.8,1.6,0.2]|\n",
            "|       2.0|  2.0|[5.2,3.4,1.4,0.2]|\n",
            "|       2.0|  2.0|[5.4,3.4,1.7,0.2]|\n",
            "|       2.0|  2.0|[5.4,3.9,1.3,0.4]|\n",
            "|       0.0|  0.0|[5.5,2.3,4.0,1.3]|\n",
            "|       2.0|  2.0|[5.5,4.2,1.4,0.2]|\n",
            "|       0.0|  0.0|[5.6,2.5,3.9,1.1]|\n",
            "|       0.0|  0.0|[5.7,2.8,4.5,1.3]|\n",
            "|       0.0|  0.0|[6.0,2.2,4.0,1.0]|\n",
            "|       0.0|  0.0|[6.1,2.8,4.7,1.2]|\n",
            "|       0.0|  0.0|[6.2,2.2,4.5,1.5]|\n",
            "+----------+-----+-----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Test accuracy =  100.0 %\n",
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  1.0|       1.0|   13|\n",
            "|  2.0|       2.0|   14|\n",
            "|  0.0|       0.0|   12|\n",
            "+-----+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meaningful-watch"
      },
      "source": [
        "### LogisticRegression Classifier "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "organized-occasions"
      },
      "source": [
        "Unfortunatly Pyspark does not handle multi class problems for the gradient boosting. I'll use the logistic regression instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "minute-eligibility"
      },
      "source": [
        "#### Prepare data for ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pharmaceutical-grave"
      },
      "source": [
        "#Transform to a Data Frame for input to Machine Learing\n",
        "\n",
        "#stage 1: as before\n",
        "#stage 2: as before \n",
        "                                  \n",
        "#stage 3: create the model \n",
        "classifier_gb = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "\n",
        "#regroup the stages in a pipeline\n",
        "pipeline_gb = Pipeline(stages=[stringIndexer, vectorAssembler, classifier_gb])\n",
        "\n",
        "# split data\n",
        "#(data_train, data_test) = iris_df.randomSplit([0.75, 0.25])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gross-skill"
      },
      "source": [
        "#### Perform Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "relevant-gilbert",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382cd9b0-b1c5-4b59-9709-8ad413bad9f3"
      },
      "source": [
        "# apply the pipeline to apply the transformation and train the model \n",
        "model_gb = pipeline_gb.fit(data_train)\n",
        "\n",
        "# make predictions by transforming the features dataframe into predictions dataframe\n",
        "predictions_gb = model_gb.transform(data_test)\n",
        "\n",
        "print(\"model info : \",model_gb.stages[-1])\n",
        "\n",
        "predictions_gb.select(\"prediction\",\"label\", \"features\").show()\n",
        "\n",
        "#Evaluate accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n",
        "                    labelCol=\"label\",metricName=\"accuracy\")\n",
        "accuracy_gb = evaluator.evaluate(predictions_gb)    \n",
        "\n",
        "print(\"Test accuracy = \", accuracy_gb*100, \"%\")\n",
        "\n",
        "#Draw a confusion matrix\n",
        "predictions_gb.groupBy(\"label\",\"prediction\").count().show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model info :  LogisticRegressionModel: uid=LogisticRegression_d6b9261ecd53, numClasses=3, numFeatures=4\n",
            "+----------+-----+-----------------+\n",
            "|prediction|label|         features|\n",
            "+----------+-----+-----------------+\n",
            "|       2.0|  2.0|[4.4,2.9,1.4,0.2]|\n",
            "|       2.0|  2.0|[4.6,3.4,1.4,0.3]|\n",
            "|       2.0|  2.0|[4.8,3.0,1.4,0.1]|\n",
            "|       2.0|  2.0|[4.8,3.1,1.6,0.2]|\n",
            "|       2.0|  2.0|[4.9,3.6,1.4,0.1]|\n",
            "|       2.0|  2.0|[5.0,3.3,1.4,0.2]|\n",
            "|       2.0|  2.0|[5.1,3.3,1.7,0.5]|\n",
            "|       2.0|  2.0|[5.1,3.5,1.4,0.2]|\n",
            "|       2.0|  2.0|[5.1,3.8,1.5,0.3]|\n",
            "|       2.0|  2.0|[5.1,3.8,1.6,0.2]|\n",
            "|       2.0|  2.0|[5.2,3.4,1.4,0.2]|\n",
            "|       2.0|  2.0|[5.4,3.4,1.7,0.2]|\n",
            "|       2.0|  2.0|[5.4,3.9,1.3,0.4]|\n",
            "|       1.0|  0.0|[5.5,2.3,4.0,1.3]|\n",
            "|       2.0|  2.0|[5.5,4.2,1.4,0.2]|\n",
            "|       1.0|  0.0|[5.6,2.5,3.9,1.1]|\n",
            "|       1.0|  0.0|[5.7,2.8,4.5,1.3]|\n",
            "|       1.0|  0.0|[6.0,2.2,4.0,1.0]|\n",
            "|       1.0|  0.0|[6.1,2.8,4.7,1.2]|\n",
            "|       1.0|  0.0|[6.2,2.2,4.5,1.5]|\n",
            "+----------+-----+-----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Test accuracy =  69.23076923076923 %\n",
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  1.0|       1.0|   13|\n",
            "|  0.0|       1.0|   12|\n",
            "|  2.0|       2.0|   14|\n",
            "+-----+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}